{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandan110791/hindiWhisper/blob/main/Whisper_LM_fusion_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtnWp1Z9NIrh"
      },
      "source": [
        "# Fusing LM with Whisper for lower WER\n",
        "The aim is to fuse a BPE-level LM scores with the generated tokens scores while beam-search decoding in Whisper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWD69559NPaz"
      },
      "source": [
        "## **MILESTONE 1**:\n",
        "Instantiate a Language Model to be integrated with Whisper.\n",
        "The chosen LM is an n-gram language model, trained with [KenLM](https://github.com/kpu/kenlm) library.\n",
        "\n",
        "### Step 1:\n",
        "Write code to run an already available LM in a standalone manner and be able to give a score any input sequence.\n",
        "**Chosen Model**: [Riva ASR Hindi LM](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN5ZcXEbPFgD"
      },
      "source": [
        "Download and build the KenLM toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOD5vBabeTED",
        "outputId": "e245aa24-055e-4895-e543-8bc2052c8c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-13 11:27:39--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 480.36K  1.67MB/s    in 0.3s    \n",
            "\n",
            "2023-11-13 11:27:40 (1.67 MB/s) - written to stdout [491888/491888]\n",
            "\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Found Boost: /usr/lib/x86_64-linux-gnu/cmake/Boost-1.74.0/BoostConfig.cmake (found suitable version \"1.74.0\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework \n",
            "-- Found Threads: TRUE  \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.8\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.5\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done (1.3s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  1%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 50%] Built target probing_hash_table_benchmark\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 57%] Built target kenlm_filter\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 75%] Built target fragment\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 77%] Built target query\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 86%] Built target kenlm_benchmark\n",
            "[ 87%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 91%] Built target kenlm_builder\n",
            "[ 92%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 93%] Built target filter\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 96%] Built target phrase_table_vocab\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "build_binary  filter\tkenlm_benchmark  phrase_table_vocab\t       query\n",
            "count_ngrams  fragment\tlmplz\t\t probing_hash_table_benchmark\n"
          ]
        }
      ],
      "source": [
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz | tar xz\n",
        "!mkdir kenlm/build && cd kenlm/build && cmake .. && make -j2\n",
        "!ls kenlm/build/bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQgYC5RKfKHp"
      },
      "source": [
        "Download the KenLM Python library\n",
        "\n",
        "❗❗**Don't forget to restart the runtime after running this cell** ❗❗\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C3lwRxNebYv",
        "outputId": "e2f9d66a-0bcc-4f1f-ab47-43bffd8fe3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.6/553.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.2.0-cp310-cp310-linux_x86_64.whl size=3184345 sha256=6cc9a5db8180947baa0ae0b8fd35c040b77ff8e307bf437b2fafd6295101aa79\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9az3r8uo/wheels/a5/73/ee/670fbd0cee8f6f0b21d10987cb042291e662e26e1a07026462\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJviLM3FcWAB"
      },
      "source": [
        "## ***Pointer 1:Please add comments on the model being downloaded and whats its purpose ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr61mDKxZru1"
      },
      "source": [
        "Downloading the Hindi ASR n-gram language model from Nvidia which can be found [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/speechtotext_hi_in_lm/files?version=deployable_v3.1)\n",
        "\n",
        "This will be used for fusion with Whisper.\n",
        "I uploaded the binary version to a shareable location in my Gdrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "NU0mgmnmhsxe",
        "outputId": "6484130f-7253-4276-9d29-58098fb08827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 147MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5LXkmNaklfx",
        "outputId": "151e2382-782e-41f4-8c8d-316b4fa00a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "import kenlm\n",
        "model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(model.order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fo71Q-qbfuU",
        "outputId": "a853e9f9-0f9d-4ed4-eb86-a3fae25a457d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-20.935253143310547 -21.663846969604492\n"
          ]
        }
      ],
      "source": [
        "# Below are 2 pairs of sentences that sound exactly the same in hindi but one of them is incorrect (lexically or semantically)\n",
        "# Generated using Bing Chat\n",
        "book_correct = \"मुझे यह किताब पसंद है।\"\n",
        "book_incorrect = \"मुझे यह किताब पसन्द है।\"\n",
        "\n",
        "correct_score = model.score(book_correct)\n",
        "incorrect_score = model.score(book_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDslvQ98bhFd",
        "outputId": "335af234-ca71-441e-f1c2-d51c10524ff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-19.827430725097656 -22.76061248779297\n"
          ]
        }
      ],
      "source": [
        "sings_correct = \"वह बहुत अच्छा गाता है।\"\n",
        "sings_incorrect = \"वह बहुत अच्छा घाता है।\"\n",
        "\n",
        "\n",
        "correct_score = model.score(sings_correct)\n",
        "incorrect_score = model.score(sings_incorrect)\n",
        "assert correct_score > incorrect_score\n",
        "print(correct_score, incorrect_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt69WiP8dIJV"
      },
      "source": [
        "## ***Pointer 2:Please elaborate on the model being downloaded and whats its purpose . Also , why are we doing it two times  ***\n",
        "\n",
        "This is unnecessary and can be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SJcuIrcggxHt",
        "outputId": "f2eafece-e032-484d-d4bf-7ad71cfd5cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4xQ3YCtsyONtpccGjOD1s9FtHqBX7RL\n",
            "To: /content/language_model_3p0.arpa\n",
            "100%|██████████| 3.18G/3.18G [00:33<00:00, 95.6MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.arpa'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # download the original arpa LM file for inspection\n",
        "# url = \"https://drive.google.com/uc?id=1-4xQ3YCtsyONtpccGjOD1s9FtHqBX7RL\"\n",
        "# output = \"language_model_3p0.arpa\"\n",
        "# gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wuzy3sEdTsq"
      },
      "source": [
        "$$:Please elaborate if we need to prepare a new arpa file for our model\n",
        "\n",
        "We can use this model for the time being, and finetune it later with the text data from our training set.\n",
        "However, I think it's not likely to come up with a better model than this, as this model is built by a team in Nvidia and it's probable that our training set is included in training this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43gXFE7Sg8kU",
        "outputId": "86667dff-df12-4421-d17b-1d376ffebb01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1.2548329\t<s> दोनों ही झल्लाये\n",
            "-0.2760634\t<s> चौधरी के अशुभचिंतकों\n",
            "-0.04973512\tडालियों पर बैठी शुकमंडली\n",
            "-0.07060567\tमनुष्यों को उन्हें बेमुरौवत\n",
            "-0.049646165\tऔर कड़क कर बोलेमेरी\n",
            "-0.04038189\tनिराश हो कर कहानहीं\n",
            "-0.08863469\tपड़ते ही वह अव्यवस्थितचित्त\n",
            "-0.19321889\tदोनों पक्षों से सवालजवाब\n",
            "-0.051110353\tझगड़ू साहु ने कहासमझू\n",
            "-0.20675866\tकरें तो उनकी भलमनसी\n",
            "-0.04876329\tनीति को सराहता थाइसे\n",
            "-0.06436408\t<s> मित्रता की मुरझायी\n",
            "-0.23735626\tकी गहराई से उपजतें\n",
            "-0.17502813\tपूर्णता की ओर बढातें\n",
            "-0.18197767\tजहाँ से अच्छा हिन्दोसिताँ\n",
            "-0.04437429\tहैं इसकी यह गुलसिताँ\n",
            "-0.06926097\tसंतरी हमारा वह पासबाँ\n",
            "-0.09434804\tजिनके दम से रश्कएजनाँ\n",
            "\n",
            "\\end\\\n"
          ]
        }
      ],
      "source": [
        "# inspect the last 20 lines inside the LM source\n",
        "!tail -20 language_model_3p0.arpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQA6huWockMP"
      },
      "outputs": [],
      "source": [
        "# some useful KenLM commands for future reference\n",
        "# generate binary\n",
        "# !kenlm/build/bin/build_binary dataset_tokenized_3gram.arpa dataset_tokenized_3gram.binary\n",
        "# create a new LM\n",
        "# !kenlm/build/bin/lmplz -o 3 --text dataset_tokenized.txt --arpa dataset_tokenized_3gram.arpa --discount_fallback\n",
        "# !tail -20 dataset_tokenized_3gram.arpa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGlHlhrffpHT"
      },
      "source": [
        "# Integrating the LM with Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKmnxRsofoXu",
        "outputId": "b9938565-d8e9-4d25-e8c4-7262cabc01c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m\\\u001b[0m \u001b[32m7.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton==2.0.0 (from openai-whisper==20231106)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Collecting lit (from triton==2.0.0->openai-whisper==20231106)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m963.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from openai-whisper==20231106)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->openai-whisper==20231106)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=799894 sha256=5cd706d6cdee8f6830cf056e88a1d63ee3addf9ed9f5475756fcf6de1929ec39\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wakv1z_z/wheels/7e/59/d2/1662a1f0ae2217e2cd01935b4ac823b4eade5c382bed87a164\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=e3f1120ba7d88a2773bd61ab328bf198c9f34c030eacff15beb2c74d23a483f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, tiktoken, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, openai-whisper\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-17.0.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 openai-whisper-20231106 tiktoken-0.5.1 torch-2.0.1 triton-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai-whisper\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28qXwUAIhQmA"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import torch\n",
        "import kenlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h061i7Dhaeq",
        "outputId": "d6884838-d9bf-4a41-bef8-d78b259d8cfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 461M/461M [00:04<00:00, 112MiB/s]\n"
          ]
        }
      ],
      "source": [
        "model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWRBxk5khiKQ",
        "outputId": "a95ab83a-f2f9-4e97-cd17-cfa061aa7d15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\n",
            "To: /content/sample.wav\n",
            "100%|██████████| 197k/197k [00:00<00:00, 77.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOZKw5wGlNWm"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd1uG_bTTeSC"
      },
      "outputs": [],
      "source": [
        "# Download a sample audio file from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kKeSvrZo8z5Rsp1q-h3GXpG7vHctKMcG\"\n",
        "output = \"sample.wav\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "transcription = \"ब्रूड बॉक्स लैंगस्ट्रॉथ छत्ते का एक अनिवार्य हिस्सा है।\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDH0eYJ8TkU4"
      },
      "outputs": [],
      "source": [
        "audio = whisper.load_audio(\"/content/sample.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmbBreqNX3IX"
      },
      "source": [
        "## Baseline Whisper\n",
        "Without nbest or LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LFz_dwKdlXyR",
        "outputId": "37969971-4d76-4717-f7c7-53447af2d18c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uew0igzbYPO"
      },
      "source": [
        "# Decoding with LM integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wAsYJNj3blQO",
        "outputId": "222b37f8-62be-4e2b-b86a-c7b1917097c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:04<00:00, 67.3MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# adding the LM\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEluDSiWd2iC"
      },
      "source": [
        "$$:\n",
        "\n",
        "## ***Pointer 4: Getting an error here while trying to run the code . Elaborate a bit on the what happening here . Can you please refer to the function with changes done  ***\n",
        "\n",
        "The error was due to the fact that the imported whisper here is the original one, which doesn't include the changed that we did to the decoding options.\n",
        "\n",
        "Replaced this:\n",
        "```\n",
        "!pip install openai-whisper\n",
        "```\n",
        "with this:\n",
        "```\n",
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "```\n",
        "\n",
        "and the error is fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVX9bKV9BaR"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=5,\n",
        "        patience=1.0, lm_path=\"/content/language_model_3p0.bin\", lm_alpha=1.0, lm_beta=0.0,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "decoding_withLM = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BPtkRefB-FUv",
        "outputId": "7bd1f8b6-1eb1-4066-f59d-95a6917af9aa"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoding_withLM.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzCM2xRb28i"
      },
      "source": [
        "# Decoding with nbest (beam search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF6AnpXkb5XM",
        "outputId": "a314a338-bb04-440b-c8ff-48efabf24b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45291578358617324\n",
            "ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45523316981428763\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है. -0.47296941078315347\n",
            "ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं -0.48318856449450476\n",
            "ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है -0.46669308344523114\n"
          ]
        }
      ],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "nbest = whisper.decode(model, mel, options)\n",
        "\n",
        "\n",
        "for candidate in nbest:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J38npjnkcDW7"
      },
      "source": [
        "### Adding LM rescoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23wLneazBit1",
        "outputId": "072daaa5-d1c2-4466-fa8d-f91450ef2d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a 4-gram model\n"
          ]
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "print(\"This is a {}-gram model\".format(lm_model.order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAdRnI_UBzWJ",
        "outputId": "44cedf0d-4d24-4c0d-fdfe-6cd16a271c6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45291578358617324,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45523316981428763,\n",
              "  -36.06303787231445),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.',\n",
              "  -0.47296941078315347,\n",
              "  -44.10427474975586),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं',\n",
              "  -0.48318856449450476,\n",
              "  -37.30411148071289),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.46669308344523114,\n",
              "  -37.54087829589844)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "nbest_with_lm_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUBQ-WVCCH1N",
        "outputId": "7b430fe5-3f6c-4549-a8a0-955bf8efc6a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8135461623093178),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8158635485374321),\n",
              " ('ब्रूद बाँक्ष लांश्टोट छत्टे का एक अनिवार्य हिस्सा है', -0.8421018664042155),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा हैं', -0.8562296793016337),\n",
              " ('ब्रूद बाँक्ष लंश्टोट छत्ते का एक अनिवार्य हिस्सा है.', -0.9140121582807121)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh5OtW5kz7gU"
      },
      "source": [
        "# Decoding with nbest (best of N hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rof-6s_mykVX"
      },
      "outputs": [],
      "source": [
        "options = whisper.DecodingOptions(fp16 = False, best_of=10, return_nbest=True, without_timestamps=True, temperature=0.3, language=\"hi\")\n",
        "nbest_best_of_n_hyp = whisper.decode(model, mel, options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuDcmFH106lC",
        "outputId": "cded2418-b2e9-4e0f-c99f-a6d14937f715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है -0.45742596898760113\n",
            "ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है -0.5202431113032971\n",
            "ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है -0.5065439448637121\n",
            "ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey. -0.9538334877260269\n",
            "ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है -0.5101523081461589\n",
            "ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है -0.4865361798194147\n",
            "ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है -0.49694071144893254\n",
            "ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है -0.5291237149919782\n",
            "ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है -0.5426437135726686\n",
            "ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है -0.49345003325363684\n"
          ]
        }
      ],
      "source": [
        "for candidate in nbest_best_of_n_hyp:\n",
        "  print(candidate.text, candidate.avg_logprob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOXOEofa2ZAe",
        "outputId": "980fca20-e1d0-4608-9c31-8ed779ab9a43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है',\n",
              "  -0.45742596898760113,\n",
              "  -35.82866668701172),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है',\n",
              "  -0.5202431113032971,\n",
              "  -49.43550491333008),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -0.5065439448637121,\n",
              "  -54.91597366333008),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -0.9538334877260269,\n",
              "  -81.96270751953125),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है',\n",
              "  -0.5101523081461589,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.4865361798194147,\n",
              "  -46.603515625),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है',\n",
              "  -0.49694071144893254,\n",
              "  -49.201133728027344),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है',\n",
              "  -0.5291237149919782,\n",
              "  -46.626407623291016),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.5426437135726686,\n",
              "  -42.747047424316406),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है',\n",
              "  -0.49345003325363684,\n",
              "  -50.678977966308594)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_model = kenlm.LanguageModel('/content/language_model_3p0.bin')\n",
        "nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest_best_of_n_hyp]\n",
        "nbest_with_lm_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIuqEbJ-2d-k",
        "outputId": "bb2afb82-8baa-45ec-a4cd-c152175916cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('ब्रूद बाँच लंश्टोट छत्ते का एक अनिवार्य हिस्सा है', -0.8157126358577182),\n",
              " ('ब्रूद बाँच लंच्टोड छत्टे का एक अनिवार्य लिए हिस्सा है',\n",
              "  -0.9525713360694148),\n",
              " ('ब्रूद भोग्ष लंग स्थ्टोड शथ्टे का एक अनिवार्य हिस्सा है',\n",
              "  -0.9701141878158327),\n",
              " ('ब्रुद बाँच लांश्टोट छद्टे का एक अनिवार्य हिस्चा है', -0.976416384379069),\n",
              " ('ब्रूद बाँच लांश्टोट छत्ते का एक अनीवार्य हिस्था है', -0.9889520487292061),\n",
              " ('ब्रूद बाँच लन्च्टोट चते का एक अनिवार्य हिस्चा है', -0.9953877912248883),\n",
              " ('ब्रूद बाँच लंश्टोट छद्टे का एक अनिवारे हिस्चा है', -1.0002398129167227),\n",
              " ('ब्रूद बाओ्छ लंश्टोट छत्ते का एक अनिवार्ये हिस्चा है', -1.014598160436598),\n",
              " ('ब्रूड़ ब्रूड़ लंच्टोट चद्ते का एक अनीवार्य लिए हिस्चा है',\n",
              "  -1.0557036814970129),\n",
              " ('ब्रुध बाँच लंश्टोट चते का एक अनिवार्य हिस morally part of the Landstorch Chhattey.',\n",
              "  -1.7734605629213394)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm_weight = 0.01\n",
        "combined_scores_bestofNSampling = [(text, whisper_score + lm_score*lm_weight) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "combined_scores_bestofNSampling.sort(key=lambda t: t[1], reverse=True)\n",
        "combined_scores_bestofNSampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcAl6kVkuSSw"
      },
      "source": [
        "# **RUN THE NOTEBOOK STARTING HERE**\n",
        "\n",
        "# The next sections include:\n",
        "- Importing a finetuned huggingface model to our codebase\n",
        "- Running the evaluation of the 4 decoding variants on the imported dataset\n",
        "- Computing the WER and CER for each of the decoding variants\n",
        "\n",
        "## The decoding strategies are:\n",
        "1. baseline decoding without LM\n",
        "2. Deep fusion of the LM with the token probabilities during beam search decoding (try to find the optimal value for lm_alpha)\n",
        "3. Shallow fusion by rescoring the N best candidates generated through beam search (try to find the optimal value for lm_weight)\n",
        "4. Shallow fusion by rescoring the N best candidates generated through greedy decoding using best of N sampling (try to find the optimal value for lm_weight and temperature)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRMuGzF1WX8",
        "outputId": "08346fe2-6a03-46da-b18e-9570aa008d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Downloading https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "\u001b[2K     \u001b[32m|\u001b[0m \u001b[32m7.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (17.0.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Using cached https://github.com/kpu/kenlm/archive/master.zip (553 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-yvrqh2x6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-yvrqh2x6\n",
            "  Resolved https://github.com/huggingface/transformers to commit 81b79818309031eca7c71f159d19dd4fb7df00ad\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.104.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.7.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.8.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (17.0.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install transformers\n",
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "# !pip install librosa\n",
        "# !pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/chandan110791/hindiWhisper/archive/master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hPYrIxCeUiK",
        "outputId": "69bbfac4-4ab4-45fc-bf05-d2c763f1c5a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Using cached https://github.com/chandan110791/hindiWhisper/archive/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.27.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20231106) (17.0.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (11.7.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20231106) (0.41.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9rpmw6hfbcf"
      },
      "source": [
        "$$\n",
        "\n",
        "$$:\n",
        "\n",
        "## ***Pointer 5: its looking for a file named as pytorchmodel.bin , it does not exists hence note  able to integrate the model : CKSINGH/whisper-small-hi-iiib tuned at : https://colab.research.google.com/github/chandan110791/HindiSpeechRecognition/blob/main/fine_tune_whisper_iiitb.ipynb#scrollTo=d7030622-caf7-4039-939b-6195cdaa2585  . Any inputs ***\n",
        "\n",
        "The reason for this is that the model file after finetuning must be pickled:\n",
        "so pytorch_model.bin should be found in this path:\n",
        "https://huggingface.co/CKSINGH/whisper-small-hi-iiib/tree/main\n",
        "\n",
        "Will use this one https://huggingface.co/sanchit-gandhi/whisper-small-hi/tree/main to make the required changes to the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PXpUd4OoS3y"
      },
      "source": [
        "## In the next cell, you need to change the repo id to your repo after generating the pytorch_model.bin (pickle format of the finetuned model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kMDX0Asjuc4e",
        "outputId": "e4992935-e8c5-4aff-fbf5-d16dbf406f27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/pytorch_model.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import whisper\n",
        "import kenlm\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "import torch\n",
        "import jiwer\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "# using pickle to serialize the map_dict\n",
        "import pickle\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "filename = \"pytorch_model.bin\"\n",
        "\n",
        "\n",
        "hf_hub_download(repo_id=\"CKSINGH/whisper-small-hi-iiib\", filename=filename, local_dir=\"/content/\")\n",
        "# hf_hub_download(repo_id=\"sanchit-gandhi/whisper-small-hi\", filename=filename, local_dir=\"/content/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKwYojN1ol9j"
      },
      "source": [
        "# Here you need to change the model size from \"small\" to \"medium\" if you finetuned the whisper-medium (as the one in this repo: https://huggingface.co/CKSINGH/whisper-small-hi-iiib/tree/main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P2IO4Vy8u4GW"
      },
      "outputs": [],
      "source": [
        "# to enable verbose printing of exceptions (+ layers matching name)\n",
        "DEBUG = False\n",
        "\n",
        "# set to True if your custom model has been trained using DDP (multi-gpu)\n",
        "# as in my case, in the custom HF model, keys have a prefix (model.)\n",
        "# it should come from the fact that I have trained on a milti-gpu machine, using DDP\n",
        "DDP_TRAINED = False\n",
        "\n",
        "# if DDP we have to add a prefix to match with the HF state_dict\n",
        "if DDP_TRAINED:\n",
        "    PREFIX = \"model.\"\n",
        "else:\n",
        "    PREFIX = \"\"\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "# the device where you're running this code\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# the name of the file with your fine-tuned model\n",
        "FINETUNED_MODEL = \"pytorch_model.bin\"\n",
        "\n",
        "# the name of the file for the serialized map_dict\n",
        "# a different name, to avoid overwrite it\n",
        "FILE_DICT = MODEL_SIZE + \"_map_dict8.pkl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q3vqObGaMSt9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def import_hf_model(finetuned_model, model_size, device, file_dict, debug=False):\n",
        "\n",
        "  def has_numbers(inputString):\n",
        "      return any(char.isdigit() for char in inputString)\n",
        "\n",
        "  # next functions are used to make sanity checks for the mappings\n",
        "\n",
        "  # get if it is encoder or decoder\n",
        "  def extract_function(key_name):\n",
        "      # encoder or decoder is the first part of the key\n",
        "      first_part = key_name.split(\".\")[0]\n",
        "\n",
        "      key_func = None\n",
        "      if first_part in [\"enconder\", \"decoder\"]:\n",
        "          key_func = first_part\n",
        "\n",
        "      return key_func\n",
        "\n",
        "  def extract_layer_num(key_name):\n",
        "      # layer num is the third piece\n",
        "      layer_num = None\n",
        "\n",
        "      if has_numbers(key_name):\n",
        "          layer_num = key_name.split(\".\")[2]\n",
        "\n",
        "      return layer_num\n",
        "\n",
        "  # check that the two keys are for layers\n",
        "  # with the same function\n",
        "  # (both encoder or both decoder)\n",
        "  # and have the same layer number\n",
        "  # this way we are super-safe (I think)\n",
        "  def sanity_check(key1, key2):\n",
        "      is_ok = True\n",
        "\n",
        "      # check same func (encoder or decoder)\n",
        "      func1 = extract_function(key1)\n",
        "      func2 = extract_function(key2)\n",
        "\n",
        "      if func1 != func2:\n",
        "          print(f\"Warning: layers seem to have different functions: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      # check same layer_num\n",
        "      layer1 = extract_layer_num(key1)\n",
        "      layer2 = extract_layer_num(key2)\n",
        "\n",
        "      if layer1 != layer2:\n",
        "          print(f\"Warning: layers seem to have different numbers: {key1},{key2}\")\n",
        "          is_ok = False\n",
        "\n",
        "      return is_ok\n",
        "\n",
        "  if not os.path.isfile(file_dict):\n",
        "    # Vanilla means: not custom trained\n",
        "    print()\n",
        "    print(\"Loading vanilla Whisper model\")\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "\n",
        "    print(\"Loading vanilla HF Model\")\n",
        "    hugging_face_model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        \"openai/whisper-\" + model_size\n",
        "    ).to(device)\n",
        "\n",
        "    # extract state-dict from both\n",
        "    state_d_openai = model.state_dict()\n",
        "    state_d_huggingface = hugging_face_model.model.state_dict()\n",
        "\n",
        "    # build the mapping between keys...\n",
        "    map_dict = {}\n",
        "    print(\"Matching layers...\")\n",
        "\n",
        "    # for every layer in OpenAI model\n",
        "    n_sanity_ok = 0\n",
        "\n",
        "    #\n",
        "    # here we're considering the cartesian product of the two state dict and try to match\n",
        "    # rules applied:\n",
        "    # 1. the two layers have the same shape\n",
        "    # 2. the two layer have the same parameters' values\n",
        "    # 3. we apply sanity check (see function above)\n",
        "    #\n",
        "    for k in tqdm(state_d_openai):\n",
        "        # find a layer in the HF model, check with j\n",
        "        for j in state_d_huggingface:\n",
        "            # where parameters have same shape and same values\n",
        "            if state_d_huggingface[j].shape == state_d_openai[k].shape:\n",
        "                if torch.all(torch.eq(state_d_huggingface[j], state_d_openai[k])).item():\n",
        "                    # found, register the mapping\n",
        "                    map_dict[k] = j\n",
        "                    # make some check and eventually print a warning\n",
        "                    if sanity_check(k, j) == True:\n",
        "                        n_sanity_ok += 1\n",
        "\n",
        "                        # if you enable thsi print you can see the name of the layer\n",
        "                        # chosen in the match and you will se that they have the same functions\n",
        "                        if debug:\n",
        "                            print(k, j)\n",
        "\n",
        "                    break\n",
        "\n",
        "\n",
        "    # check if we have matched every entry\n",
        "    print(\"Check if we have matched every entry in state_dict...\")\n",
        "    print()\n",
        "    print(f\"Number of keys: {len(map_dict.keys())}\")\n",
        "    assert len(map_dict.keys()) == len(state_d_openai.keys()), \"The match is not complete !\"\n",
        "\n",
        "    print(f\"Number of sanity_check ok: {n_sanity_ok}\")\n",
        "    print()\n",
        "\n",
        "    print(\"Match is complete !!!\")\n",
        "    print()\n",
        "\n",
        "\n",
        "    # serialize the map_dict to file\n",
        "    print(\"Serializing map_dict...\")\n",
        "\n",
        "    with open(file_dict, \"wb\") as f:\n",
        "        pickle.dump(map_dict, f)\n",
        "        f.close()\n",
        "\n",
        "    print(f\"map_dict saved as: {file_dict}...\")\n",
        "    print()\n",
        "\n",
        "  else:\n",
        "    # loading with match keys\n",
        "    # restart from pickle file\n",
        "    print(\"Reloading map_dict...\")\n",
        "    print()\n",
        "    with open(file_dict, \"rb\") as f:\n",
        "        map_dict = pickle.load(f)\n",
        "\n",
        "  # loading fine-tuned dict\n",
        "  print(\"Loading fine tuned dict...\")\n",
        "\n",
        "  # added map_location to handle the fact that the custom model has been trained on GPU\n",
        "  state_dict_finetuned = torch.load(finetuned_model, map_location=torch.device(device))\n",
        "\n",
        "  print(state_dict_finetuned.keys())\n",
        "  # build the state_dict to be used\n",
        "  # take the key name from standard (OpenAI) and the value from finetuned (HF)\n",
        "  print(\"Rebuild the state dict...\")\n",
        "  new_state_dict = {}\n",
        "  n_except = 0\n",
        "  for k in tqdm(map_dict.keys()):\n",
        "      try:\n",
        "        # You must add \"model.\" if you have used DDP in custom training\n",
        "        # see DDP_TRAINED above\n",
        "        # PREFIX is added to a HF fine-tuned 8with DDP). It is not in vanulla HF models\n",
        "        new_state_dict[k] = state_dict_finetuned[PREFIX + map_dict[k]]\n",
        "      except Exception as ex:\n",
        "        n_except += 1\n",
        "\n",
        "        if debug:\n",
        "            print(\"exception\")\n",
        "            print(PREFIX + map_dict[k])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  msg_err = f\"Rebuild state dict failed, {n_except} pick failed\"\n",
        "  assert n_except == 0, msg_err\n",
        "\n",
        "\n",
        "\n",
        "  print()\n",
        "  print(\"Loading the final model...\")\n",
        "  model.load_state_dict(new_state_dict)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCxqmfBJvE__",
        "outputId": "434769b1-0794-4e5f-9699-08ef1dc6d0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading vanilla Whisper model\n",
            "Loading vanilla HF Model\n",
            "Matching layers...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:01<00:00, 265.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if we have matched every entry in state_dict...\n",
            "\n",
            "Number of keys: 479\n",
            "Number of sanity_check ok: 479\n",
            "\n",
            "Match is complete !!!\n",
            "\n",
            "Serializing map_dict...\n",
            "map_dict saved as: small_map_dict8.pkl...\n",
            "\n",
            "Loading fine tuned dict...\n",
            "odict_keys(['encoder.conv1.weight', 'encoder.conv1.bias', 'encoder.conv2.weight', 'encoder.conv2.bias', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.6.self_attn.k_proj.weight', 'encoder.layers.6.self_attn.v_proj.weight', 'encoder.layers.6.self_attn.v_proj.bias', 'encoder.layers.6.self_attn.q_proj.weight', 'encoder.layers.6.self_attn.q_proj.bias', 'encoder.layers.6.self_attn.out_proj.weight', 'encoder.layers.6.self_attn.out_proj.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.fc1.weight', 'encoder.layers.6.fc1.bias', 'encoder.layers.6.fc2.weight', 'encoder.layers.6.fc2.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.7.self_attn.k_proj.weight', 'encoder.layers.7.self_attn.v_proj.weight', 'encoder.layers.7.self_attn.v_proj.bias', 'encoder.layers.7.self_attn.q_proj.weight', 'encoder.layers.7.self_attn.q_proj.bias', 'encoder.layers.7.self_attn.out_proj.weight', 'encoder.layers.7.self_attn.out_proj.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.fc1.weight', 'encoder.layers.7.fc1.bias', 'encoder.layers.7.fc2.weight', 'encoder.layers.7.fc2.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.8.self_attn.k_proj.weight', 'encoder.layers.8.self_attn.v_proj.weight', 'encoder.layers.8.self_attn.v_proj.bias', 'encoder.layers.8.self_attn.q_proj.weight', 'encoder.layers.8.self_attn.q_proj.bias', 'encoder.layers.8.self_attn.out_proj.weight', 'encoder.layers.8.self_attn.out_proj.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.fc1.weight', 'encoder.layers.8.fc1.bias', 'encoder.layers.8.fc2.weight', 'encoder.layers.8.fc2.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.9.self_attn.k_proj.weight', 'encoder.layers.9.self_attn.v_proj.weight', 'encoder.layers.9.self_attn.v_proj.bias', 'encoder.layers.9.self_attn.q_proj.weight', 'encoder.layers.9.self_attn.q_proj.bias', 'encoder.layers.9.self_attn.out_proj.weight', 'encoder.layers.9.self_attn.out_proj.bias', 'encoder.layers.9.self_attn_layer_norm.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.fc1.weight', 'encoder.layers.9.fc1.bias', 'encoder.layers.9.fc2.weight', 'encoder.layers.9.fc2.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.10.self_attn.k_proj.weight', 'encoder.layers.10.self_attn.v_proj.weight', 'encoder.layers.10.self_attn.v_proj.bias', 'encoder.layers.10.self_attn.q_proj.weight', 'encoder.layers.10.self_attn.q_proj.bias', 'encoder.layers.10.self_attn.out_proj.weight', 'encoder.layers.10.self_attn.out_proj.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.fc1.weight', 'encoder.layers.10.fc1.bias', 'encoder.layers.10.fc2.weight', 'encoder.layers.10.fc2.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.11.self_attn.k_proj.weight', 'encoder.layers.11.self_attn.v_proj.weight', 'encoder.layers.11.self_attn.v_proj.bias', 'encoder.layers.11.self_attn.q_proj.weight', 'encoder.layers.11.self_attn.q_proj.bias', 'encoder.layers.11.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.out_proj.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.fc1.weight', 'encoder.layers.11.fc1.bias', 'encoder.layers.11.fc2.weight', 'encoder.layers.11.fc2.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layer_norm.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.6.self_attn.v_proj.weight', 'decoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.6.self_attn.q_proj.weight', 'decoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.6.self_attn.out_proj.weight', 'decoder.layers.6.self_attn.out_proj.bias', 'decoder.layers.6.self_attn_layer_norm.weight', 'decoder.layers.6.self_attn_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.fc1.weight', 'decoder.layers.6.fc1.bias', 'decoder.layers.6.fc2.weight', 'decoder.layers.6.fc2.bias', 'decoder.layers.6.final_layer_norm.weight', 'decoder.layers.6.final_layer_norm.bias', 'decoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.7.self_attn.v_proj.weight', 'decoder.layers.7.self_attn.v_proj.bias', 'decoder.layers.7.self_attn.q_proj.weight', 'decoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.7.self_attn.out_proj.weight', 'decoder.layers.7.self_attn.out_proj.bias', 'decoder.layers.7.self_attn_layer_norm.weight', 'decoder.layers.7.self_attn_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.fc1.weight', 'decoder.layers.7.fc1.bias', 'decoder.layers.7.fc2.weight', 'decoder.layers.7.fc2.bias', 'decoder.layers.7.final_layer_norm.weight', 'decoder.layers.7.final_layer_norm.bias', 'decoder.layers.8.self_attn.k_proj.weight', 'decoder.layers.8.self_attn.v_proj.weight', 'decoder.layers.8.self_attn.v_proj.bias', 'decoder.layers.8.self_attn.q_proj.weight', 'decoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.8.self_attn.out_proj.weight', 'decoder.layers.8.self_attn.out_proj.bias', 'decoder.layers.8.self_attn_layer_norm.weight', 'decoder.layers.8.self_attn_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.fc1.weight', 'decoder.layers.8.fc1.bias', 'decoder.layers.8.fc2.weight', 'decoder.layers.8.fc2.bias', 'decoder.layers.8.final_layer_norm.weight', 'decoder.layers.8.final_layer_norm.bias', 'decoder.layers.9.self_attn.k_proj.weight', 'decoder.layers.9.self_attn.v_proj.weight', 'decoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.9.self_attn.q_proj.weight', 'decoder.layers.9.self_attn.q_proj.bias', 'decoder.layers.9.self_attn.out_proj.weight', 'decoder.layers.9.self_attn.out_proj.bias', 'decoder.layers.9.self_attn_layer_norm.weight', 'decoder.layers.9.self_attn_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.fc1.weight', 'decoder.layers.9.fc1.bias', 'decoder.layers.9.fc2.weight', 'decoder.layers.9.fc2.bias', 'decoder.layers.9.final_layer_norm.weight', 'decoder.layers.9.final_layer_norm.bias', 'decoder.layers.10.self_attn.k_proj.weight', 'decoder.layers.10.self_attn.v_proj.weight', 'decoder.layers.10.self_attn.v_proj.bias', 'decoder.layers.10.self_attn.q_proj.weight', 'decoder.layers.10.self_attn.q_proj.bias', 'decoder.layers.10.self_attn.out_proj.weight', 'decoder.layers.10.self_attn.out_proj.bias', 'decoder.layers.10.self_attn_layer_norm.weight', 'decoder.layers.10.self_attn_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.fc1.weight', 'decoder.layers.10.fc1.bias', 'decoder.layers.10.fc2.weight', 'decoder.layers.10.fc2.bias', 'decoder.layers.10.final_layer_norm.weight', 'decoder.layers.10.final_layer_norm.bias', 'decoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.11.self_attn.v_proj.weight', 'decoder.layers.11.self_attn.v_proj.bias', 'decoder.layers.11.self_attn.q_proj.weight', 'decoder.layers.11.self_attn.q_proj.bias', 'decoder.layers.11.self_attn.out_proj.weight', 'decoder.layers.11.self_attn.out_proj.bias', 'decoder.layers.11.self_attn_layer_norm.weight', 'decoder.layers.11.self_attn_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.fc1.weight', 'decoder.layers.11.fc1.bias', 'decoder.layers.11.fc2.weight', 'decoder.layers.11.fc2.bias', 'decoder.layers.11.final_layer_norm.weight', 'decoder.layers.11.final_layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layer_norm.bias'])\n",
            "Rebuild the state dict...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 479/479 [00:00<00:00, 1075520.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading the final model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = import_hf_model(finetuned_model=FINETUNED_MODEL, debug= False, model_size=MODEL_SIZE, device=DEVICE, file_dict=FILE_DICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aYbjC3224bE",
        "outputId": "08611d5b-33a0-4942-d491-2c7f6f2ca1da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Whisper(\n",
              "  (encoder): AudioEncoder(\n",
              "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): TextDecoder(\n",
              "    (token_embedding): Embedding(51865, 768)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x ResidualAttentionBlock(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (cross_attn): MultiHeadAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4eGVNxPC5U7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "8536aa41d17347508a262bbc9693b7f8",
            "ba507efc55c145419acdec6f0fb62b2e",
            "f96cd823f757434997f49f4b2c7d2a04",
            "3f065f61e9e1443a85aee518670a4fa7",
            "ba67e8ff964d4073b870e1200a87fd4c",
            "ab9c06e19a154517b4ff46c7a52d29d4",
            "150486309a0540b0a51a96664f78aba7",
            "773b457557fd4352a317068d87fa4eef",
            "b805718a8b76423386511730e0fdeaff",
            "ab1471db6c574235ac5967dd80734786",
            "ff114fffeab840c6a8fab1662d1dddd7",
            "24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "e543d211badc4d41bd944df904ce0317",
            "d6ef36d77a09460d82ce46f28df66665",
            "c16fa1150d12439688fa21af50d995c7",
            "aed79d83bbe84ba5aa53f601588c4ee8",
            "28b858b805f54292a322d13611833c33",
            "7d5806a46c454e0c9c3f1ca5f70d4279",
            "455bae593a3240d9ba064c213a90ece9",
            "ba5939381af044029e254989149974db",
            "75a0a08417de42e88bdf8ffc693f42b6",
            "bb853deecb594dad80ae466afa531d75",
            "920da0787e654f6bb9a0c76cc88f0f5c",
            "bbb0d45741c8401b819941a9eda1c1a7",
            "b8b595673f6a4db4a47a25e88ebc2d4e",
            "981bc86f56014362942f1fad9d5fe00c",
            "a0f33f70e05d4897aac484cb940392d4",
            "4928327c81124c60bd8e3aca15942167",
            "7390656d2d4240969f6202876d1a57c7",
            "f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "273a08df24d343a7a227d09b9e23ebb4",
            "3dd766dafea94135862b6e9e0d9876cf"
          ]
        },
        "id": "rasFuIlSix6U",
        "outputId": "32a54d14-6a4d-4a6a-803d-dd495eb93801"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8536aa41d17347508a262bbc9693b7f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "# #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\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RGPaVW4glVi"
      },
      "source": [
        "$$:\n",
        "\n",
        "$$\n",
        "\n",
        "$$:\n",
        "\n",
        "## ***Pointer 6: We need to evaluate and calculate the WER,CER  on the Test data shared using our final model . Below are some boiler plates code to do the same  ***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-VwhKrCShjPP"
      },
      "outputs": [],
      "source": [
        "#Prepare Test Data for calculating Wer and CER\n",
        "\n",
        "import datasets\n",
        "# import the load_dataset function\n",
        "from datasets import load_dataset\n",
        "\n",
        "# specify the URL directory and the data files\n",
        "# load the dataset from the URL directory\n",
        "\n",
        "\n",
        "# datasets.config.DEFAULT_MAX_BATCH_SIZE = 10\n",
        "test_dataset = load_dataset(\"/content/datadownload.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WEu6KbZ7jGuc"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_dataset.remove_columns([\"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\",\"accents\",\"variant\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5FfCeYtjqT3",
        "outputId": "b2e880c1-5834-4dad-dafd-7e4e5db54962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 4630\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 3072\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 2416\n",
              "    })\n",
              "    other: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 3767\n",
              "    })\n",
              "    validated: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 10173\n",
              "    })\n",
              "    invalidated: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2lZFQrXajmrd"
      },
      "outputs": [],
      "source": [
        "combined_dataset = datasets.concatenate_datasets([test_dataset[\"test\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-sMtUIcj2Gj",
        "outputId": "7640a6fd-1fa1-4e68-8a32-b607cc842ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Dataset: 3041 samples\n",
            "Test Dataset: 31 samples\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, concatenate_datasets, DatasetDict, load_metric\n",
        "\n",
        "# Define the split ratios\n",
        "#train_split = 0.75  # 80% of the data\n",
        "validation_split = 0.99  # 10% of the data\n",
        "test_split = 0.1  # 10% of the data\n",
        "\n",
        "# Compute the number of samples for each split\n",
        "num_samples = len(combined_dataset)\n",
        "num_validation = int(validation_split * num_samples)\n",
        "num_test = num_samples - num_validation  # Remaining 10%\n",
        "\n",
        "# Split the combined dataset\n",
        "validation_dataset = combined_dataset.select(indices=list(range(num_validation)))\n",
        "test_dataset = combined_dataset.select(indices=list(range(num_validation, num_samples)))\n",
        "\n",
        "# If you want to organize the split datasets in a DatasetDict for convenience:\n",
        "split_test_datasets = DatasetDict({\n",
        "    'validation': validation_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Verify the resulting datasets\n",
        "print(f'Validation Dataset: {len(validation_dataset)} samples')\n",
        "print(f'Test Dataset: {len(test_dataset)} samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADERPSIplyje"
      },
      "outputs": [],
      "source": [
        "## you can use only 10% of the data to perform evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1A0idxikYWX",
        "outputId": "0200272b-4692-4422-b8e5-394471b03c20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/9274dfa08465814d9b528cc161d00ba351615d0fffa64a36a31ba4eef3620161/cv-corpus-15.0-2023-09-08/hi/Zclips/common_voice_hi_36482276.mp3',\n",
              "  'array': array([-8.88178420e-16, -1.50990331e-14, -4.44089210e-15, ...,\n",
              "          2.29964789e-05,  2.15262316e-05,  1.06726802e-05]),\n",
              "  'sampling_rate': 48000},\n",
              " 'sentence': 'हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल कांडा को नहीं मिली जगह'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "split_test_datasets[\"test\"][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmZe8mxxkrHG"
      },
      "source": [
        "Evaluation Metrics on the Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T5Zpz_I3qpQM"
      },
      "outputs": [],
      "source": [
        "class customDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A simple class to wrap LibriSpeech and trim/pad the audio to 30 seconds.\n",
        "    It will drop the last few seconds of a very small portion of the utterances.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, device=DEVICE):\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        # audio, sample_rate, text, _, _, _ = self.dataset[item]\n",
        "        # assert sample_rate == 16000\n",
        "        # audio = whisper.pad_or_trim(audio.flatten()).to(self.device)\n",
        "        # mel = whisper.log_mel_spectrogram(audio)\n",
        "        audio = self.dataset[item]['audio']\n",
        "        sentence = self.dataset[item]['sentence']\n",
        "        path = audio['path']\n",
        "        # array = audio['array']\n",
        "        # sampling_rate = audio['sampling_rate']\n",
        "        audio = whisper.load_audio(path)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "        return (mel, sentence)\n",
        "\n",
        "dataset = customDataset(split_test_datasets[\"test\"])\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "comYI3DN-Ff_"
      },
      "outputs": [],
      "source": [
        "def decode_baseline(model, mel, beam_size):\n",
        "  \"\"\"\n",
        "    This function performs the transcription with Whisper to provide a baseline without LM fusion\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n",
        "\n",
        "def decode_deep_fusion(model, mel, beam_size, lm_path, lm_alpha):\n",
        "  \"\"\"\n",
        "    This function performs the deep fusion of the LM with Whisper during the beam search decoding step\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_alpha: A numerical value representing the weight assigned to the language model scores during deep fusion.\n",
        "  \"\"\"\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, withlm=True, beam_size=beam_size,\n",
        "        patience=1.0, lm_path=lm_path, lm_alpha=lm_alpha, lm_beta=0.0,\n",
        "        without_timestamps=True, language=\"hi\")\n",
        "  result = whisper.decode(model, mel, options)\n",
        "  result = [r.text for r in result]\n",
        "  return result\n",
        "\n",
        "def decode_shallow_fusion_beam_search(model, mel, beam_size, lm_path, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - beam_size: An integer specifying the size of the beam for beam search decoding.\n",
        "    - lm_path: A string representing the path to the language model file used for fusion.\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful for inspecting the outputs with different lm_weights for finding the optimal value for lm_weight\n",
        "\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, beam_size=beam_size, return_nbest = True, without_timestamps=True, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "    nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "    combined_score = [(text, whisper_score + lm_score*lm_weight, whisper_score, lm_score) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "    combined_score.sort(key=lambda t: t[1], reverse=True)\n",
        "    combined_scores.append(combined_score)\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  #result = [combined_score[0] for combined_score in combined_scores]\n",
        "  result = [hyp for hyp, comb_score, w_score, lm_score in combined_scores]\n",
        "  #return text\n",
        "  return result[0]\n",
        "\n",
        "def decode_shallow_fusion_nbest(model, mel, best_of, lm_path, temperature, lm_weight, debug=False):\n",
        "  \"\"\"\n",
        "    this function performs shallow fusion using best of N hypothesis (greedy decoding)\n",
        "    by combining the scores of whisper and the language model score (which gets weighted by the lm_weight factor)\n",
        "\n",
        "    - model: The Whisper model used for transcription.\n",
        "    - mel: Represents Mel-spectrogram data, likely input features for the model.\n",
        "    - best_of: An integer specifying the number of best hypotheses to consider during decoding.\n",
        "    - lm_path: A string representing the path to the language model used for fusion.\n",
        "    - temperature: A numerical value indicating the temperature parameter used during sampling. Higher temperature corresponds to more variation in the n best list\n",
        "    - lm_weight: A numerical value representing the weight assigned to the language model scores during shallow fusion.\n",
        "    - debug: A boolean flag (optional) indicating whether to print debug information (default is False).\n",
        "      Useful when finding the optimal value for the lm_weight\n",
        "  \"\"\"\n",
        "  # if testing with a single utterance without a dataloader\n",
        "  if mel.shape[0] != 1:\n",
        "    mel = torch.unsqueeze(mel, 0)\n",
        "  options = whisper.DecodingOptions(fp16 = False, best_of=best_of, return_nbest=True, without_timestamps=True, temperature=temperature, language=\"hi\")\n",
        "  nbests = whisper.decode(model, mel, options)\n",
        "\n",
        "  lm_model = kenlm.LanguageModel(lm_path)\n",
        "  combined_scores = []\n",
        "\n",
        "  for nbest in nbests:\n",
        "    nbest_with_lm_score = [(c.text, c.avg_logprob, lm_model.score(c.text)) for c in nbest]\n",
        "    combined_score = [(text, whisper_score + lm_score*lm_weight, whisper_score, lm_score) for text, whisper_score, lm_score in nbest_with_lm_score]\n",
        "    combined_score.sort(key=lambda t: t[1], reverse=True)\n",
        "    combined_scores.append(combined_score)\n",
        "  if debug:\n",
        "    print(combined_scores)\n",
        "  # text, final_score, whisper_score, lm_score = combined_scores[0]\n",
        "  # return the highest score element for each input in the batch\n",
        "  result = [combined_score[0] for combined_score in combined_scores]\n",
        "  #return text\n",
        "  return result[0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzkjrcWnZTIE"
      },
      "source": [
        "# Decoding without LM as a baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pP3luWRsuxxh",
        "outputId": "769dc26e-0533-4c44-d889-6e717fe48f1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:53<00:00,  1.72s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-85404d11-34ab-4f89-bd35-bbafd89242b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हरियाणा मनोहरलाल खट्टर की कैबिनेट में गोपाल का...</td>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...</td>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...</td>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...</td>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मध्य प्रदेश चलती ट्रेन में युगती से रेप</td>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...</td>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>टॉम ने तो दरवाजा बंद तट नहीं किया</td>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>चैनल चार लगाइए</td>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद</td>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार</td>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>फोन पर पिता से इटली बात करते करते बेटे ने दे द...</td>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान</td>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि</td>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...</td>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>मुझे लगा मै यहाँ अकेला हूँ</td>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>दिनों केहिं जाल में फँसते भुजबल</td>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...</td>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>अपने बच्चों के लिए सम्पत्ति नहीं छोड़ेंगे बिल ...</td>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...</td>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>भखवान के भरोसे धार्मिक भीड</td>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके</td>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>मोदी युग में पीजेपी का प्रवेश</td>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय</td>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर</td>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>राजियाबाद लड़की की मिली लाश रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>दिल्ली येप के माह ने कार लोट की कोशिश डाइवर कु...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85404d11-34ab-4f89-bd35-bbafd89242b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85404d11-34ab-4f89-bd35-bbafd89242b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85404d11-34ab-4f89-bd35-bbafd89242b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3364cb88-9db3-4196-b645-10a1928163b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3364cb88-9db3-4196-b645-10a1928163b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3364cb88-9db3-4196-b645-10a1928163b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8c99f2c2-a016-4ea0-a3eb-874036eb0a89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('baseline_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c99f2c2-a016-4ea0-a3eb-874036eb0a89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('baseline_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   हरियाणा मनोहरलाल खट्टर की कैबिनेट में गोपाल का...   \n",
              "1   कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...   \n",
              "2   क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...   \n",
              "3   इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...   \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...   \n",
              "5             मध्य प्रदेश चलती ट्रेन में युगती से रेप   \n",
              "6   दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...   \n",
              "7                   टॉम ने तो दरवाजा बंद तट नहीं किया   \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...   \n",
              "9                                      चैनल चार लगाइए   \n",
              "10    आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद   \n",
              "11  घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार   \n",
              "12  फोन पर पिता से इटली बात करते करते बेटे ने दे द...   \n",
              "13     तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान   \n",
              "14                   कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि   \n",
              "15  मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...   \n",
              "16                         मुझे लगा मै यहाँ अकेला हूँ   \n",
              "17                    दिनों केहिं जाल में फँसते भुजबल   \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...   \n",
              "19  अपने बच्चों के लिए सम्पत्ति नहीं छोड़ेंगे बिल ...   \n",
              "20  कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...   \n",
              "21                         भखवान के भरोसे धार्मिक भीड   \n",
              "22      कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके   \n",
              "23                      मोदी युग में पीजेपी का प्रवेश   \n",
              "24     तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय   \n",
              "25     जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर   \n",
              "26           राजियाबाद लड़की की मिली लाश रेप की आशंका   \n",
              "27    जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया   \n",
              "28  दिल्ली येप के माह ने कार लोट की कोशिश डाइवर कु...   \n",
              "29  डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...   \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                            reference  \n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...  \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...  \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...  \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...  \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...  \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप  \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...  \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।  \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...  \n",
              "9                                    चैनल चार लगाइये।  \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी  \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल  \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान  \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...  \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे  \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...  \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।  \n",
              "17                    अपनों के ही जाल में फंसते भुजबल  \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...  \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...  \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...  \n",
              "21                        भगवान के भरोसे धार्मिक भीड़  \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके  \n",
              "23                      मोदी युग में बीजेपी का प्रवेश  \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय  \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...  \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 5\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_baseline(model, mel, beam_size)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "baseline_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "baseline_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVpt-nocar5T",
        "outputId": "bc5037d5-5df4-475d-effe-e6adb0c12e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WER: 37.59 %\n",
            "CER: 10.83 %\n"
          ]
        }
      ],
      "source": [
        "\n",
        "wer = jiwer.wer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(baseline_df[\"reference\"]), list(baseline_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DrvdKNZZfV"
      },
      "source": [
        "# Decoding with LM deep fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "dEfO8QAbbdKO",
        "outputId": "422cf661-6683-4d1e-c49e-8b87e104ae5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:03<00:00, 81.6MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'language_model_3p0.bin'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HisMIkZzYJjJ",
        "outputId": "7f80ab94-186d-4560-cdfb-9db2428de649"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [23:30<00:00, 45.51s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5e63133-994e-40ff-9a30-b234f87c1ea6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हरियाणा मनोहर लाल खट्टर की कैबिनेट में गोपाल क...</td>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...</td>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...</td>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...</td>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मध्य प्रदेश चलती ट्रेन में युगती से रेप</td>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...</td>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>टॉम ने तो दरवाजा बंद तट नहीं किया</td>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>चैनल चार लगाइए</td>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद</td>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार</td>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>फोन पर पिता से इटली बात करते करते बेटे ने दे द...</td>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान</td>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि</td>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...</td>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>मुझे लगा मैं यहाँ केला हूँ</td>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>दिनों केहिं जाल में फँसते भुजबल</td>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...</td>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...</td>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>भखवान के भरोसे धार्मिक भीड</td>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके</td>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>मोदी युग में पीजेपी का प्रवेश</td>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय</td>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर</td>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>राजियाबाद लड़की की मिली लाश रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>दिल्ली येप के माह ने कार लोट की कोशिश डायवर कु...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5e63133-994e-40ff-9a30-b234f87c1ea6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5e63133-994e-40ff-9a30-b234f87c1ea6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5e63133-994e-40ff-9a30-b234f87c1ea6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11c7d983-865e-40ab-892e-8297397bc99c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11c7d983-865e-40ab-892e-8297397bc99c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11c7d983-865e-40ab-892e-8297397bc99c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   हरियाणा मनोहर लाल खट्टर की कैबिनेट में गोपाल क...   \n",
              "1   कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुल...   \n",
              "2   क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया क...   \n",
              "3   इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर ...   \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...   \n",
              "5             मध्य प्रदेश चलती ट्रेन में युगती से रेप   \n",
              "6   दिल्ली महिरा सेफ से रेब की कोशिश नाकाम हुआ तो ...   \n",
              "7                   टॉम ने तो दरवाजा बंद तट नहीं किया   \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...   \n",
              "9                                      चैनल चार लगाइए   \n",
              "10    आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद   \n",
              "11  घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार   \n",
              "12  फोन पर पिता से इटली बात करते करते बेटे ने दे द...   \n",
              "13     तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान   \n",
              "14                   कॉलेज ऑफ इवेंट्स एंड मीडिया पुनि   \n",
              "15  मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जायेगी च...   \n",
              "16                         मुझे लगा मैं यहाँ केला हूँ   \n",
              "17                    दिनों केहिं जाल में फँसते भुजबल   \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उ...   \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...   \n",
              "20  कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवन्...   \n",
              "21                         भखवान के भरोसे धार्मिक भीड   \n",
              "22      कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके   \n",
              "23                      मोदी युग में पीजेपी का प्रवेश   \n",
              "24     तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय   \n",
              "25     जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर   \n",
              "26           राजियाबाद लड़की की मिली लाश रेप की आशंका   \n",
              "27    जेट डेट एयरवेअर के कार्यवाग सीओ ने इस्तीफा दिया   \n",
              "28  दिल्ली येप के माह ने कार लोट की कोशिश डायवर कु...   \n",
              "29  डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना ...   \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                            reference  \n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...  \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...  \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...  \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...  \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...  \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप  \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...  \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।  \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...  \n",
              "9                                    चैनल चार लगाइये।  \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी  \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल  \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान  \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...  \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे  \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...  \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।  \n",
              "17                    अपनों के ही जाल में फंसते भुजबल  \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...  \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...  \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...  \n",
              "21                        भगवान के भरोसे धार्मिक भीड़  \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके  \n",
              "23                      मोदी युग में बीजेपी का प्रवेश  \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय  \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...  \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_alpha = 0.2\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    # result = decode_baseline(model, mel, beam_size)\n",
        "    result = decode_deep_fusion(model, mel, beam_size=beam_size, lm_path=lm_path, lm_alpha=lm_alpha)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "deep_fusion_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "deep_fusion_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0DWNREhg6ol"
      },
      "source": [
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 15\n",
        "lm_alpha = 0.5\n",
        "\n",
        "WER: 37.24 %\n",
        "CER: 10.83 %\n",
        "\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 15\n",
        "lm_alpha = 1.5\n",
        "\n",
        "WER: 37.24 %\n",
        "CER: 10.83 %\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpu45C9BblyC",
        "outputId": "e3ebfdf2-d6c4-4fcc-bd58-78b7d87f3ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WER: 36.55 %\n",
            "CER: 10.76 %\n"
          ]
        }
      ],
      "source": [
        "wer = jiwer.wer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(deep_fusion_df[\"reference\"]), list(deep_fusion_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8jjEY_BZc0X"
      },
      "source": [
        "# Decoding with shallow fusion (Beam Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "V3FQ3GHMIq9h",
        "outputId": "eb55f8ca-6b81-4915-9f32-928c9b41f38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\n",
            "To: /content/language_model_3p0.bin\n",
            "100%|██████████| 280M/280M [00:01<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'language_model_3p0.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Download the binary LM from Gdrive\n",
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1-AspJVZRXcrFMuLKx8C4N7uo9PnQytcB\"\n",
        "output = \"language_model_3p0.bin\"\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQvvnm2IYfK_",
        "outputId": "bc3508df-7c82-405b-b7ab-dbe931d21c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [01:56<00:00,  3.75s/it]\n"
          ]
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.05\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "    #exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "-lOP4glqbuEO",
        "outputId": "671332bb-1ec1-42c5-d74c-68eee7382e65"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f7eebb5f275f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjiwer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshallow_fusion_beam_search_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjiwer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_fusion_beam_search_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reference\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_fusion_beam_search_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hypothesis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjiwer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_fusion_beam_search_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reference\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_fusion_beam_search_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hypothesis\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ],
      "source": [
        "import jiwer\n",
        "\n",
        "shallow_fusion_beam_search_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "wer = jiwer.wer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(shallow_fusion_beam_search_df[\"reference\"]), list(shallow_fusion_beam_search_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NrMKme91SNKl",
        "outputId": "68469b38-04d7-4503-d49f-6617a6f007fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-756824fd-bb40-42ed-8556-beae51539789\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>तमिलनाडु में आतंकियों की मदद के आरोप में संदिग...</td>\n",
              "      <td>तमिलनाडु में आतंकियों की मदद के आरोप में संदिग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>सेमीफाइनल में भी दिखेगा युवराज का जलवा, फिट घोषित</td>\n",
              "      <td>सेमीफाइनल में भी दिखेगा युवराज का जलवा, फिट घोषित</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>मोर्गन नॉटिंघम वनडे से निलंबित, बेयरस्टो को लग...</td>\n",
              "      <td>मोर्गन नॉटिंघम वनडे से निलंबित, बेयरस्टो को लग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>नोटबंदी पर 'पलटूराम': पहले किया सपोर्ट, फिर मा...</td>\n",
              "      <td>नोटबंदी पर 'पलटूराम': पहले किया सपोर्ट, फिर मा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>आंखों के लिए फायदेमंद है योग, ऐसे करें अभ्यास</td>\n",
              "      <td>आंखों के लिए फायदेमंद है योग, ऐसे करें अभ्यास</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-756824fd-bb40-42ed-8556-beae51539789')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-756824fd-bb40-42ed-8556-beae51539789 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-756824fd-bb40-42ed-8556-beae51539789');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d53c55c1-0be2-41f8-a5a2-7372da16df0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d53c55c1-0be2-41f8-a5a2-7372da16df0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d53c55c1-0be2-41f8-a5a2-7372da16df0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            hypothesis  \\\n",
              "0    तमिलनाडु में आतंकियों की मदद के आरोप में संदिग...   \n",
              "1    सेमीफाइनल में भी दिखेगा युवराज का जलवा, फिट घोषित   \n",
              "2    मोर्गन नॉटिंघम वनडे से निलंबित, बेयरस्टो को लग...   \n",
              "3    नोटबंदी पर 'पलटूराम': पहले किया सपोर्ट, फिर मा...   \n",
              "4        आंखों के लिए फायदेमंद है योग, ऐसे करें अभ्यास   \n",
              "..                                                 ...   \n",
              "763         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका   \n",
              "764       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया   \n",
              "765  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...   \n",
              "766  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...   \n",
              "767  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                             reference  \n",
              "0    तमिलनाडु में आतंकियों की मदद के आरोप में संदिग...  \n",
              "1    सेमीफाइनल में भी दिखेगा युवराज का जलवा, फिट घोषित  \n",
              "2    मोर्गन नॉटिंघम वनडे से निलंबित, बेयरस्टो को लग...  \n",
              "3    नोटबंदी पर 'पलटूराम': पहले किया सपोर्ट, फिर मा...  \n",
              "4        आंखों के लिए फायदेमंद है योग, ऐसे करें अभ्यास  \n",
              "..                                                 ...  \n",
              "763         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "764       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "765  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "766  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "767  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  \n",
              "\n",
              "[768 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shallow_fusion_beam_search_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo2EsdZtwoYE",
        "outputId": "d6442f7c-e85d-4816-ed7b-e07bfa6f78c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install jiwer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b20hHgyUZjJk"
      },
      "source": [
        "# Decoding with shallow fusion (Best of N hypothesis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbMCA5lSGuQA",
        "outputId": "c1b393bf-3b14-405b-850a-0ca7c7798e3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:54<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           hypothesis  \\\n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...   \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...   \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...   \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...   \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...   \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप   \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...   \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।   \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...   \n",
              "9                                    चैनल चार लगाइये।   \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी   \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल   \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान   \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...   \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे   \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...   \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।   \n",
              "17                    अपनों के ही जाल में फंसते भुजबल   \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...   \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...   \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...   \n",
              "21                        भगवान के भरोसे धार्मिक भीड़   \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके   \n",
              "23                      मोदी युग में बीजेपी का प्रवेश   \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय   \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...   \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका   \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया   \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...   \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...   \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...   \n",
              "\n",
              "                                            reference  \n",
              "0   हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...  \n",
              "1   कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...  \n",
              "2   क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...  \n",
              "3   इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...  \n",
              "4   कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...  \n",
              "5            मध्य प्रदेश: चलती ट्रेन में युवती से रेप  \n",
              "6   दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...  \n",
              "7                 टॉम ने तो दरवाज़ा बंद तक नहीं किया।  \n",
              "8   पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...  \n",
              "9                                    चैनल चार लगाइये।  \n",
              "10   आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी  \n",
              "11   घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल  \n",
              "12   फोन पर पिता से इटली बात करते-करते बेटे ने दी जान  \n",
              "13  ...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...  \n",
              "14                  कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे  \n",
              "15  'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...  \n",
              "16                       मुझे लगा मैं यहां अकेला हूं।  \n",
              "17                    अपनों के ही जाल में फंसते भुजबल  \n",
              "18  श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...  \n",
              "19  अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...  \n",
              "20  कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...  \n",
              "21                        भगवान के भरोसे धार्मिक भीड़  \n",
              "22      कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके  \n",
              "23                      मोदी युग में बीजेपी का प्रवेश  \n",
              "24   तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय  \n",
              "25  जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...  \n",
              "26         गाजियाबाद: लड़की की मिली लाश, रेप की आशंका  \n",
              "27       जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया  \n",
              "28  दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...  \n",
              "29  डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...  \n",
              "30  श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd6f9e4-ee29-41b4-bb0b-f16eff1bd8aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "      <td>हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "      <td>कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, प...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "      <td>क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "      <td>इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "      <td>कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "      <td>मध्य प्रदेश: चलती ट्रेन में युवती से रेप</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "      <td>दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "      <td>टॉम ने तो दरवाज़ा बंद तक नहीं किया।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "      <td>पति के खर्राटों के कारण पत्नी गंवाती है तीन सप...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "      <td>चैनल चार लगाइये।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "      <td>आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "      <td>घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "      <td>फोन पर पिता से इटली बात करते-करते बेटे ने दी जान</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "      <td>...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "      <td>कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "      <td>'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' क...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "      <td>मुझे लगा मैं यहां अकेला हूं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "      <td>अपनों के ही जाल में फंसते भुजबल</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "      <td>श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "      <td>अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल ग...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "      <td>कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्न...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "      <td>भगवान के भरोसे धार्मिक भीड़</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "      <td>कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "      <td>मोदी युग में बीजेपी का प्रवेश</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "      <td>तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "      <td>जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफो...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "      <td>गाजियाबाद: लड़की की मिली लाश, रेप की आशंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "      <td>जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "      <td>दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "      <td>डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना च...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "      <td>श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd6f9e4-ee29-41b4-bb0b-f16eff1bd8aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cd6f9e4-ee29-41b4-bb0b-f16eff1bd8aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cd6f9e4-ee29-41b4-bb0b-f16eff1bd8aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c29bacbc-5499-49cd-8119-7bb41439605c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c29bacbc-5499-49cd-8119-7bb41439605c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c29bacbc-5499-49cd-8119-7bb41439605c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# decoding parameters you can try playing around with to reach the optimal WER\n",
        "best_of = 10\n",
        "temperature = 0.3\n",
        "lm_weight = 0.01\n",
        "\n",
        "for mel, text in tqdm(loader):\n",
        "    # results = model.decode(mels, options)\n",
        "    # hypotheses.extend([result.text for result in results])\n",
        "    result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "    hypotheses.extend(result)\n",
        "    references.extend(text)\n",
        "\n",
        "\n",
        "shallow_fusion_nbest_df = pd.DataFrame(dict(hypothesis=hypotheses, reference=references))\n",
        "shallow_fusion_nbest_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szELTfXRmCUk",
        "outputId": "aaccaf2a-0b33-4ffd-d8b9-ac9a2fab2935"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-THVa9cm3Gj",
        "outputId": "9dee4059-c828-4138-857d-2f1cedb0a7bd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['हरियाणा: मनोहर लाल खट्टर की कैबिनेट में गोपाल कांडा को नहीं मिली जगह',\n",
              " 'कासगंज हिंसा: आरोपी राहत कुरैशी भी गिरफ्तार, पुलिस पूछताछ में जुटी',\n",
              " \"क्या आपने देखा राधिका आप्टे की फिल्म 'फोबिया' का टीजर\",\n",
              " 'इंफोसिस ऑफिस में महिला इंजीनियर की कंप्यूटर के तार से गला घोंटकर हत्या',\n",
              " 'कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा करेंगे राहुल',\n",
              " 'मध्य प्रदेश: चलती ट्रेन में युवती से रेप',\n",
              " 'दिल्ली: महिला शेफ से रेप की कोशिश, नाकाम हुआ तो चौथी मंजिल से फेंका',\n",
              " 'टॉम ने तो दरवाज़ा बंद तक नहीं किया।',\n",
              " 'पति के खर्राटों के कारण पत्नी गंवाती है तीन सप्ताह की नींद',\n",
              " 'चैनल चार लगाइये।',\n",
              " 'आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से सनसनी',\n",
              " 'घुसपैठ पर सेना प्रमुख के बयान से मचा सियासी बवाल',\n",
              " 'फोन पर पिता से इटली बात करते-करते बेटे ने दी जान',\n",
              " '...तो इस वजह से कपिल के शो पर नहीं जाएंगे ‘सुल्तान’',\n",
              " 'कॉलेज ऑफ इवेंट्स एंड मीडिया, पुणे',\n",
              " \"'मणिशंकर अय्यर टी स्टाल' में लीजिए 'नमो चाय' की चुस्कियां\",\n",
              " 'मुझे लगा मैं यहां अकेला हूं।',\n",
              " 'अपनों के ही जाल में फंसते भुजबल',\n",
              " 'श्रीदेवी की मौत की जांच संबंधी याचिका खारिज, उठाया था ये सवाल',\n",
              " 'अपने बच्चों के लिए संपत्ति नहीं छोड़ेंगे बिल गेट्स',\n",
              " 'कर्नाटक चुनाव: होलेनरसिंहपुरा सीट पर दो रेवन्ना के बीच चुनावी जंग',\n",
              " 'भगवान के भरोसे धार्मिक भीड़',\n",
              " 'कोलकाता: छात्रों ने मोंटेक सिंह पर अंडे फेंके',\n",
              " 'मोदी युग में बीजेपी का प्रवेश',\n",
              " 'तारीखों पर दुबारा विचार करे आईपीएल: गृह मंत्रालय',\n",
              " 'जम्मू-कश्मीर: आतंकवादियों के ठिकानों का भंडाफोड़, विस्फोटक बरामद',\n",
              " 'गाजियाबाद: लड़की की मिली लाश, रेप की आशंका',\n",
              " 'जेट एयरवेज के कार्यवाहक सीईओ ने इस्तीफा दिया',\n",
              " 'दिल्लीः लिफ्ट के बहाने कार लूट की कोशिश, ड्राइवर को मारी गोली',\n",
              " 'डोकलाम विवाद के बाद भारत से लंबी दोस्ती करना चाहता है चीन',\n",
              " 'श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने की खुदकुशी']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUi57A1SmR0E",
        "outputId": "5d801037-ef20-4cee-c17e-630ea568745e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['हरियाणा मनोहर लाल खट्टर की कैबिनेट में गोपाल कांडा को नहीं मिली जगहा',\n",
              " -0.41793007135391236,\n",
              " -0.010053408145904542,\n",
              " -40.78766632080078,\n",
              " 'कासकंज हिंसा आरोपी राहत कोरैशी भी गिरफ्तार पुलिस पूँछ ताछ में जुड़ी',\n",
              " -0.628240288016084,\n",
              " -0.018196228262665985,\n",
              " -61.0044059753418,\n",
              " 'क्या आपने देखा राधि का आपदे के फ़िल्म फोबिया का टीजर',\n",
              " -0.4918291026970436,\n",
              " -0.020716126622824835,\n",
              " -47.111297607421875,\n",
              " 'इन्फोसिव सॉफिस में महिला इंजीनियर की कंप्यूटर के तार से गला घोटकर हत्या',\n",
              " -0.5373387240074776,\n",
              " -0.04611252771841513,\n",
              " -49.12261962890625,\n",
              " 'कांग्रेस की उम्मीदें परवान चढ़ाने को पदयात्रा करेंगे राहुल',\n",
              " -0.329933881405741,\n",
              " -0.006149167660623789,\n",
              " -32.37847137451172,\n",
              " 'मध्य प्रदेश चलती ट्रेन में युगती से रेप',\n",
              " -0.2934632857008414,\n",
              " -0.005557707087560134,\n",
              " -28.790557861328125,\n",
              " 'दिल्ली महिरा शेख से रेब की कोशिश नाकाम हुआ तो चौकी मंजर से फेंका',\n",
              " -0.623125996518491,\n",
              " -0.04700256817376436,\n",
              " -57.612342834472656,\n",
              " 'टॉम ने तो दरवाजा बंद तट नहीं किया',\n",
              " -0.2719667205061668,\n",
              " -0.002617431565737113,\n",
              " -26.93492889404297,\n",
              " 'पति के खर्राटों के कारण पत्नी गंवाती है तीन सप्ताह की नीति',\n",
              " -0.4764313024487989,\n",
              " -0.03345229091315434,\n",
              " -44.29790115356445,\n",
              " 'चैनल चार लगाइए',\n",
              " -0.17484052720822787,\n",
              " -0.02715845170773958,\n",
              " -14.768207550048828,\n",
              " 'आधी रात को दिल्ली हवाई अड्डे पर फायरिंग से संसद',\n",
              " -0.24617892656188745,\n",
              " -0.002671121691281979,\n",
              " -24.350780487060547,\n",
              " 'घुसपैड पर सेना प्रमुख के बयां से मचा सिया सी बवार',\n",
              " -0.5081148180594811,\n",
              " -0.016036189519442044,\n",
              " -49.207862854003906,\n",
              " 'फोन पर पिता से इटली बात करते करते बेटे ने दे दी जान',\n",
              " -0.4034628497293362,\n",
              " -0.0029375659158596625,\n",
              " -40.052528381347656,\n",
              " 'तो इस वजह से कपिल के सोपर नहीं जायेंगे सुल्तान',\n",
              " -0.31862010808701213,\n",
              " -0.0017290863584964833,\n",
              " -31.689102172851562,\n",
              " 'कॉलेज ऑफ इवेंट्स एंड मीडिया पुणे',\n",
              " -0.2752850673256851,\n",
              " -0.04559730029687649,\n",
              " -22.96877670288086,\n",
              " 'मणिशंकर अय्यर टीएस टॉल में लीजिये नमो जाएगी चुस्कियाँ',\n",
              " -0.4915698296023953,\n",
              " -0.042291837353860176,\n",
              " -44.927799224853516,\n",
              " 'मुझे लगा मैं यहाँ अकेला हूँ',\n",
              " -0.1893104949593544,\n",
              " -0.0183778777718544,\n",
              " -17.09326171875,\n",
              " 'दिनों के ही जाल में फँसते भुजबल',\n",
              " -0.4176988113627714,\n",
              " -0.10647898561814252,\n",
              " -31.12198257446289,\n",
              " 'श्रीदेवी की मौत की जांच संबंधी याचि का खाडिश उठाया था ये सवाल',\n",
              " -0.44826695498298197,\n",
              " -0.0200652795679429,\n",
              " -42.820167541503906,\n",
              " 'अपने बच्चों के लिए सम्पत्ति नहीं छोड़ेंगे बिल गेट्स',\n",
              " -0.2750355146328608,\n",
              " -0.011899966994921367,\n",
              " -26.313554763793945,\n",
              " 'कर्नाटक चुनाव होले नरसिन्हापुरा सीट पर दोरेवनना के बीच चुनावी जंग',\n",
              " -0.495234969371074,\n",
              " -0.0336892540390427,\n",
              " -46.154571533203125,\n",
              " 'भखवान के भरोसे धार्मिक भीड',\n",
              " -0.2980627187093099,\n",
              " -0.03163426717122396,\n",
              " -26.642845153808594,\n",
              " 'कोल काता छात्रों ने मॉन्टिक सिंह पर अंडे फेके',\n",
              " -0.4692812225093012,\n",
              " -0.04641630856887154,\n",
              " -42.28649139404297,\n",
              " 'मोदी युग में पीजेपी का प्रवेश',\n",
              " -0.2161485543208463,\n",
              " -0.00018366479447909763,\n",
              " -21.59648895263672,\n",
              " 'तारीखो पर दोबारा विचार करे आईपीएल गृह मंत्रालय',\n",
              " -0.3199211584604703,\n",
              " -0.0076026045359098,\n",
              " -31.231855392456055,\n",
              " 'जम्मू कश्मीर आतंकवादियों के ठिकानों का भंडाफुर',\n",
              " -0.2895474518262423,\n",
              " -0.027328995557931755,\n",
              " -26.221845626831055,\n",
              " 'राजियाबाद लड़की की मिली लाश रेप की आशंका',\n",
              " -0.34831892211800036,\n",
              " -0.003521940306476925,\n",
              " -34.479698181152344,\n",
              " 'जेट एयरवेअर के कार्यवाग सीओनएँ ने इस्तीफा दिया',\n",
              " -0.48703658245227954,\n",
              " -0.1225273432555022,\n",
              " -36.450923919677734,\n",
              " 'दिल्ली येप के माह ने कार लोट की कोशिश डाइवर कुमारी बोली',\n",
              " -0.5942400641276918,\n",
              " -0.05202952335620749,\n",
              " -54.22105407714844,\n",
              " 'डोकलाम विवाद के बाद भारत से लम्बी दोस्ती करना चाहता है चीन',\n",
              " -0.3112444241841634,\n",
              " -0.017600568135579427,\n",
              " -29.3643856048584,\n",
              " 'श्रीनगर आतंकी हमले में शहीद सैनिक की पत्नी ने की खुद खुशी',\n",
              " -0.3353981352845828,\n",
              " -0.00670463095108668,\n",
              " -32.86935043334961]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "lBnxUSwUbyeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04418465-2eb5-4784-d131-2169ffa86c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WER: 0.00 %\n",
            "CER: 0.00 %\n"
          ]
        }
      ],
      "source": [
        "wer = jiwer.wer(list(shallow_fusion_nbest_df[\"reference\"]), list(shallow_fusion_nbest_df[\"hypothesis\"]))\n",
        "cer = jiwer.cer(list(shallow_fusion_nbest_df[\"reference\"]), list(shallow_fusion_nbest_df[\"hypothesis\"]))\n",
        "\n",
        "print(f\"WER: {wer * 100:.2f} %\")\n",
        "print(f\"CER: {cer * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkA9HqG-nkvq"
      },
      "source": [
        "# **Pointer 7 ## Final code t o push our model to hugging face **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gratepG_lcQP"
      },
      "outputs": [],
      "source": [
        "##Code to push the final model to hugging face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQYFfgqeJY2_"
      },
      "outputs": [],
      "source": [
        "kwargs = {\n",
        "    \"language\": \"hi\",\n",
        "    \"model_name\": \"Whisper integrated LM 2011\",  # a 'pretty' name for our model\n",
        "    \"finetuned_from\": \"openai/whisper-medium\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "    \"tags\": \"hf-asr-leaderboard\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "09E9_ZIjJesT",
        "outputId": "775aebba-7f12-4e13-9cdf-41b2ed78d45f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a10d0a24e70c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Whisper' object has no attribute 'push_to_hub'"
          ]
        }
      ],
      "source": [
        "model.push_to_hub(**kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKtFtijYJmbi"
      },
      "source": [
        "**##Inferences of model vs BenchMarkModels -wave2wec and GoogleUSM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF8NmdKLKDpZ"
      },
      "source": [
        "**##Orignal  Whisper Model without any integration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlk1fACOKBaL",
        "outputId": "4b241e34-fd31-4b6e-9923-5f8fcc6a262b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=dd836e0126dac7c20ed84b460d598c223253b0b252cf89883aa6e023ff0895f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4f2gCnpLG23",
        "outputId": "c3bf09a1-f754-4b38-b860-763d3a9ac56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " अमाना नाम चंदिन कमार स्टिंग है, और हम राची से चारकंच्टेड है, आमार.\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model = whisper.load_model(\"small\")  # You can choose different model sizes like \"tiny\", \"small\", \"medium\", \"large\"\n",
        "\n",
        "# Transcribe the audio file\n",
        "result = model.transcribe(\"/content/audio.wav\",language=\"hi\")\n",
        "\n",
        "# Print the transcription\n",
        "print(result[\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiu-YU40Jtam"
      },
      "source": [
        "[link text](https://)**##Orignal Integrated Whisper Model without fusion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jZwwkj6cUDyd",
        "outputId": "69c22e37-d278-4534-a945-cb39dc190338"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inferencing using audio files\n",
        "##Code to perform call compute metrics on test dataset using our final model and calculate the WER and CER\n",
        "\n",
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.05\n",
        "audio = whisper.load_audio(\"/content/audio.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "options = whisper.DecodingOptions(fp16 = False, beam_size=5, without_timestamps=True, language=\"hi\")\n",
        "result = whisper.decode(model, mel, options)\n",
        "baseline = result.text\n",
        "baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with shallow fusion and beam search**"
      ],
      "metadata": {
        "id": "k0vV7a8Kpnon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "a1bjiBonW5KE",
        "outputId": "8d47c101-0dd5-473a-bd71-b7907670881f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट', -0.4159112863373338, -0.07522887514348615, -34.068241119384766), ('हमारा नाम चंदन कुमार सिंह और हम राज्य से झारखंड स्टेट याम', -0.4201896166801453, -0.06313570737838745, -35.70539093017578), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट याम', -0.4260845669762033, -0.019786234761847824, -40.62983322143555), ('हमारा नाम चंदन कुमार सिंह और हम रांची से झारखंड स्टेट याम', -0.43641326427459715, -0.0646193265914917, -37.17939376831055), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट हैम', -0.4581754334767659, -0.05169571240743001, -40.647972106933594), ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट याम', -0.45854578831156745, -0.049068630718794026, -40.947715759277344), ('हमारा नाम चन्दन कुमार सिंह और हम राँची से झारखंड स्टेट हैम', -0.4752447270565346, -0.06497426502040175, -41.02704620361328), ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट हैम', -0.4932946713765462, -0.08363612492879231, -40.96585464477539), ('हमारा नाम चंदन कुमार सिंघ्यार्म', -0.5001224985989657, -0.2906207171353427, -20.950178146362305), ('हमारा नाम चंदन कुमार सिंह और हम राँची से झारखंड स्टेट हाम', -0.5059090073903402, -0.09262970288594564, -41.32793045043945)]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-b62129b4f512>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_mel_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# decode_baseline decode_shallow_fusion_beam_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_shallow_fusion_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-83415cf212ad>\u001b[0m in \u001b[0;36mdecode_shallow_fusion_beam_search\u001b[0;34m(model, mel, beam_size, lm_path, lm_weight, debug)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# return the highest score element for each input in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m#result = [combined_score[0] for combined_score in combined_scores]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhyp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;31m#return text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-83415cf212ad>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# return the highest score element for each input in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m#result = [combined_score[0] for combined_score in combined_scores]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhyp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomb_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_scores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;31m#return text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ],
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 0.01\n",
        "audio = whisper.load_audio(\"/content/audio_2.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# decode_baseline decode_shallow_fusion_beam_search\n",
        "result = decode_shallow_fusion_beam_search(model, mel, beam_size=beam_size, lm_path=lm_path, lm_weight=lm_weight,debug=True)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#Orignal Integrated Whisper Model with shallow fusion and greedy decoding:**"
      ],
      "metadata": {
        "id": "oEKn50DSpuO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypotheses = []\n",
        "references = []\n",
        "\n",
        "best_of = 10\n",
        "temperature = 1.0\n",
        "lm_weight = 1.0\n",
        "\n",
        "lm_path = '/content/language_model_3p0.bin'\n",
        "# # decoding parameters you can try playing around with to reach the optimal WER\n",
        "beam_size = 20\n",
        "lm_weight = 1.0\n",
        "audio = whisper.load_audio(\"/content/audio_2.wav\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "# decode_baseline decode_shallow_fusion_beam_search\n",
        "result = decode_shallow_fusion_nbest(model, mel, best_of=best_of, lm_path=lm_path, temperature=temperature, lm_weight=lm_weight, debug=False)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Xp3eU7jIp3",
        "outputId": "59359960-bf48-4b29-db54-46b494bd8bb5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('हमारा नाम चन्दन कुमार सिंह और हम रांची से झारखंड स्टेट याम',\n",
              " -37.63978749415914,\n",
              " -0.08131962916890129,\n",
              " -37.558467864990234)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-ofgIloKYdf"
      },
      "source": [
        "**##Orignal Wave2wec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hXopFc9cSJj",
        "outputId": "a582763e-a286-455a-852e-d0adedceed71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:733: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*******************wave 2 wec transcription***************** \n",
            "CHAMMUSHAA U CHACHA TRU I'L SHAR\n"
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "import torch\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "# Function to read and preprocess the audio file\n",
        "def speech_file_to_array_fn(path):\n",
        "    speech_array, sampling_rate = sf.read(path)\n",
        "    return speech_array\n",
        "\n",
        "# Function to perform inference\n",
        "def asr_transcript(audio_file):\n",
        "    # Load and preprocess the audio\n",
        "    speech = speech_file_to_array_fn(audio_file)\n",
        "    input_values = tokenizer(speech, return_tensors=\"pt\", padding=\"longest\").input_values\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    # Get predicted IDs and decode them to text\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = tokenizer.batch_decode(predicted_ids)\n",
        "\n",
        "    return transcription[0]\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file = \"/content/audio.wav\"\n",
        "\n",
        "# Perform inference and print the result\n",
        "print(\"*******************wave 2 wec transcription***************** \")\n",
        "print(asr_transcript(audio_file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jpnOwYUKc15"
      },
      "source": [
        "**Orignal Google USM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "uDfTKL4PeFSy",
        "outputId": "9f8ada34-3a73-4011-bdf3-e4cca5084763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-speech\n",
            "  Downloading google_cloud_speech-2.22.0-py2.py3-none-any.whl (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/275.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/275.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (1.22.3)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-speech) (3.20.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.61.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.59.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-speech) (0.5.0)\n",
            "Installing collected packages: google-cloud-speech\n",
            "Successfully installed google-cloud-speech-2.22.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Google USM\n",
        "\n",
        "!pip install google-cloud-speech\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbqDGYN2IfwI"
      },
      "source": [
        "##Google USM Transcrption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW125a12CNY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drivedownloaduplaod-eed71df0371c.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z16bfD3FE3Tb",
        "outputId": "4b1ef210-3db6-49cc-d216-66ea2afffca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4jPhZZeRH0CM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "84dd55a1-f7f0-48d8-afd2-336919c7a6f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-0618ad8a1598>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from . import (  # noqa: F401\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0m_extension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcompliance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_extension/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0m_IS_ALIGN_AVAILABLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_IS_TORCHAUDIO_EXT_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchaudio\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchaudio\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_extension/utils.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchaudio/lib/libtorchaudio.so: undefined symbol: _ZN3c104cuda9SetDeviceEi"
          ]
        }
      ],
      "source": [
        "import torchaudio\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "# Load the audio file\n",
        "waveform, sample_rate = torchaudio.load('/content/audio_4.wav')\n",
        "\n",
        "# Resample to 16kHz\n",
        "resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "resampled_waveform = resampler(waveform)\n",
        "\n",
        "# Save the resampled audio\n",
        "torchaudio.save('resampled_audio.wav', resampled_waveform, 16000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S58lF2odEu9x",
        "outputId": "44d6eb86-3a14-4187-d982-2eb6186967ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/audio.flac'>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Load the WAV file\n",
        "wav_audio = AudioSegment.from_file(\"/content/resampled_audio.wav\", format=\"wav\")\n",
        "\n",
        "# Export as FLAC\n",
        "wav_audio.export(\"/content/audio.flac\", format=\"flac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsdZEHzrePRj",
        "outputId": "4fcf129f-aa56-4746-e51b-73b447b9755a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"alternatives\": [\n",
            "        {\n",
            "          \"transcript\": \"हमारा नाम चंदन कुमार सिंह है और हम रांची से झारखंड स्टेट नाम है\",\n",
            "          \"confidence\": 0.8868657\n",
            "        }\n",
            "      ],\n",
            "      \"resultEndTime\": \"6.760s\",\n",
            "      \"languageCode\": \"hi-in\"\n",
            "    }\n",
            "  ],\n",
            "  \"totalBilledTime\": \"7s\",\n",
            "  \"requestId\": \"9093070027649121811\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!curl -s -H \"Content-Type: application/json\" \\\n",
        "    -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
        "    https://speech.googleapis.com/v1/speech:recognize \\\n",
        "    -d @sync-request.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ('हमारा नाम चंदन कुमार सिंह और हम राँजी से झारखंड स्टेट हैम',"
      ],
      "metadata": {
        "id": "4LMRTYILlyJY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "150486309a0540b0a51a96664f78aba7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "24c1c8f49f5a43eab9b1b9f9f0a12fc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273a08df24d343a7a227d09b9e23ebb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b858b805f54292a322d13611833c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd766dafea94135862b6e9e0d9876cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f065f61e9e1443a85aee518670a4fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_24c1c8f49f5a43eab9b1b9f9f0a12fc4",
            "style": "IPY_MODEL_e543d211badc4d41bd944df904ce0317",
            "value": true
          }
        },
        "455bae593a3240d9ba064c213a90ece9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4928327c81124c60bd8e3aca15942167": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7390656d2d4240969f6202876d1a57c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a0a08417de42e88bdf8ffc693f42b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b595673f6a4db4a47a25e88ebc2d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_981bc86f56014362942f1fad9d5fe00c",
            "value": "Token is valid (permission: write)."
          }
        },
        "773b457557fd4352a317068d87fa4eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5806a46c454e0c9c3f1ca5f70d4279": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455bae593a3240d9ba064c213a90ece9",
            "placeholder": "​",
            "style": "IPY_MODEL_ba5939381af044029e254989149974db",
            "value": "Connecting..."
          }
        },
        "8536aa41d17347508a262bbc9693b7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75a0a08417de42e88bdf8ffc693f42b6",
              "IPY_MODEL_bb853deecb594dad80ae466afa531d75",
              "IPY_MODEL_920da0787e654f6bb9a0c76cc88f0f5c",
              "IPY_MODEL_bbb0d45741c8401b819941a9eda1c1a7"
            ],
            "layout": "IPY_MODEL_150486309a0540b0a51a96664f78aba7"
          }
        },
        "920da0787e654f6bb9a0c76cc88f0f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7390656d2d4240969f6202876d1a57c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f0885c2a4abd4fe6902ca4f7aba7b2a1",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "981bc86f56014362942f1fad9d5fe00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0f33f70e05d4897aac484cb940392d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1471db6c574235ac5967dd80734786": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9c06e19a154517b4ff46c7a52d29d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed79d83bbe84ba5aa53f601588c4ee8",
            "placeholder": "​",
            "style": "IPY_MODEL_28b858b805f54292a322d13611833c33",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "aed79d83bbe84ba5aa53f601588c4ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b805718a8b76423386511730e0fdeaff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b595673f6a4db4a47a25e88ebc2d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba507efc55c145419acdec6f0fb62b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773b457557fd4352a317068d87fa4eef",
            "placeholder": "​",
            "style": "IPY_MODEL_b805718a8b76423386511730e0fdeaff",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ba5939381af044029e254989149974db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba67e8ff964d4073b870e1200a87fd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d6ef36d77a09460d82ce46f28df66665",
            "style": "IPY_MODEL_c16fa1150d12439688fa21af50d995c7",
            "tooltip": ""
          }
        },
        "bb853deecb594dad80ae466afa531d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0f33f70e05d4897aac484cb940392d4",
            "placeholder": "​",
            "style": "IPY_MODEL_4928327c81124c60bd8e3aca15942167",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "bbb0d45741c8401b819941a9eda1c1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273a08df24d343a7a227d09b9e23ebb4",
            "placeholder": "​",
            "style": "IPY_MODEL_3dd766dafea94135862b6e9e0d9876cf",
            "value": "Login successful"
          }
        },
        "c16fa1150d12439688fa21af50d995c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d6ef36d77a09460d82ce46f28df66665": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e543d211badc4d41bd944df904ce0317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0885c2a4abd4fe6902ca4f7aba7b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f96cd823f757434997f49f4b2c7d2a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ab1471db6c574235ac5967dd80734786",
            "placeholder": "​",
            "style": "IPY_MODEL_ff114fffeab840c6a8fab1662d1dddd7",
            "value": ""
          }
        },
        "ff114fffeab840c6a8fab1662d1dddd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}